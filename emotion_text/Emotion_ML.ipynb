{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Оглавление\n",
        "\n",
        "[1. Импорт модуля и загрузка датафрейма](#Импорт-модуля-и-загрузка-датафрейма)\n",
        "<br>[2. Деление на тренировочную, валидационную и тестовую выборки](#Train,-test,-valid)\n",
        "<br>[3. Лемматизция текста](#Лемматизация-текста)\n",
        "<br>[4. Удаление стоп-слов](#Удаление-стоп-слов)\n",
        "<br>[5. Преобразование в TF-IDF вектора](#Преобразование-в-TF-IDF-вектора)\n",
        "<br>[6. Обучение модели логистической регрессии](#Обучение-модели-логистической-регрессии)\n",
        "<br>[7. Запись модели в файл](#Запись-модели-в-файл)\n",
        "<br>[8. Загрузка модели из файла](#Загрузка-модели-из-файла)\n",
        "<br>[9. Предсказание эмоции для заданного текста](#Предсказание-эмоции-для-заданного-текста)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Импорт модуля и загрузка датафрейма"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\morri\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "from tqdm import tqdm\n",
        "from emotion_text import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qfrCmICm_2w6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                text  label\n",
            "0  i feel awful about it too because it s my job ...      0\n"
          ]
        }
      ],
      "source": [
        "df = open_file('data.jsonl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "#df_sampl = df.head(100).copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train, test, valid\n",
        "Делим датасет на тренировочную, валидационную и тестовую выборки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "iaw8dF15Lyde"
      },
      "outputs": [],
      "source": [
        "X_train, y_train, X_test, X_val, y_test, y_val = train_test_val(df.text, df.label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Лемматизация текста"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkK9yPE5Zb53",
        "outputId": "0fcc44f0-6cd3-42e9-f22c-8fec41ebda3f"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, X_val = lemmatize_text(X_train, X_test, X_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Удаление стоп-слов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bT1Sin6oYYw4",
        "outputId": "0ca55ecc-5ca2-41d1-d756-deaf723d2b7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "49    really hoping get target soon glad im feeling ...\n",
            "Name: text, dtype: object\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, X_val = stopwords_text(X_train, X_test, X_val, language = 'english', num_row=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Преобразование в TF-IDF вектора"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42q_jo0V-fCu"
      },
      "outputs": [],
      "source": [
        "X_train_tfidf, X_test_tfidf, X_val_tfidf, vectorizer = tf_idf_vec(X_train, X_test, X_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CUm_fuXiDO4"
      },
      "source": [
        "## Обучение модели логистической регрессии"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-yPLtnh0-8xd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 49/49 [00:00<00:00, 88.57it/s] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Максимальный f1_score = 0.32727272727272727, полученный при значении С = 2.3000000000000003 на тестовой выборке\n",
            "Максимальный f1_score = 0.2071794871794872, полученный при значении С = 2.4000000000000004 на валидационной выборке\n",
            "Максимальный accuracy = 0.35, полученный при значении С = 2.3000000000000003 на тестовой выборке\n",
            "Максимальный accuracy = 0.3, полученный при значении С = 0.4 на валидационной выборке\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for C in tqdm(np.arange(0.1, 5.0, 0.1)):\n",
        "    \n",
        "    model_LogisticRegression_L2 = LogisticRegression(class_weight='balanced',\n",
        "                                                     multi_class='multinomial', \n",
        "                                                     max_iter = 1000, \n",
        "                                                     solver='lbfgs', \n",
        "                                                     penalty='l2', \n",
        "                                                     C=C)\n",
        "    learning_model(X_train_tfidf, y_train, X_val_tfidf, y_val, X_test_tfidf, y_test, model_LogisticRegression_L2, C)\n",
        "print_score(max_f1_test, max_f1_valid, max_acc_test, max_acc_valid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Запись модели в файл"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('model.pkl', 'wb') as f:\n",
        "    pickle.dump(model_LogisticRegression_L2, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Загрузка модели из файла"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('model.pkl', 'rb') as f:\n",
        "    model = pickle.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YGb82T_pbw0"
      },
      "source": [
        "## Предсказание эмоции для заданного текста"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "word = 'my day bad'\n",
        "\n",
        "word_tfidf = vectorizer.transform([word])\n",
        "vanga = model.predict(word_tfidf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You are sadness, be happy!\n"
          ]
        }
      ],
      "source": [
        "vanga_answers(vanga)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
