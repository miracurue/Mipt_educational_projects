{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Для работы необходимо загрузить следующие файлы:\n",
        "\n",
        "<br>model.pkl\n",
        "<br>vectorizer.pickle\n",
        "<br>emotion_text.py\n",
        "<br>anger.wav"
      ],
      "metadata": {
        "id": "osirt7eNCafC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYMjGhWj_iVA"
      },
      "source": [
        "# Оглавление\n",
        "\n",
        "[1. Импорт модулей](#Импорт-модулей)\n",
        "<br>[2. Распознавание файла и конвертация в текст](#Распознавание-файла-и-конвертация-в-текст)\n",
        "<br>[3. Загрузка модели из файла](#Загрузка-модели-из-файла)\n",
        "<br>[4. Предсказание эмоции для заданного текста](#Предсказание-эмоции-для-заданного-текста)\n",
        "<br>[5. Загрузка датафрейма](#Загрузка-датафрейма)\n",
        "<br>[6. Деление на тренировочную, валидационную и тестовую выборки](#Train,-test,-valid)\n",
        "<br>[7. Лемматизция текста](#Лемматизация-текста)\n",
        "<br>[8. Удаление стоп-слов](#Удаление-стоп-слов)\n",
        "<br>[9. Преобразование в TF-IDF вектора](#Преобразование-в-TF-IDF-вектора)\n",
        "<br>[10. Обучение модели логистической регрессии](#Обучение-модели-логистической-регрессии)\n",
        "<br>[11. Запись модели в файл](#Запись-модели-в-файл)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Импорт модулей"
      ],
      "metadata": {
        "id": "EWHX1amTA9wn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydub\n",
        "!apt-get install ffmpeg\n",
        "!pip install SpeechRecognition\n",
        "\n",
        "\n",
        "from pydub import AudioSegment\n",
        "import io\n",
        "import speech_recognition as sr\n",
        "import os  # Импортируем модуль os\n",
        "\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "from emotion_text import *\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eie12IkQXYoR",
        "outputId": "739fcd2e-5828-4fdd-f179-3a805ff0e373"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 24 not upgraded.\n",
            "Collecting SpeechRecognition\n",
            "  Downloading SpeechRecognition-3.10.1-py2.py3-none-any.whl (32.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2023.11.17)\n",
            "Installing collected packages: SpeechRecognition\n",
            "Successfully installed SpeechRecognition-3.10.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Распознавание файла и конвертация в текст"
      ],
      "metadata": {
        "id": "-kMOeB_JBYXE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Конвертация MP3 в WAV\n",
        "# Ваш MP3-файл должен быть предварительно загружен в Colab\n",
        "mp3_file = '/content/anger.mp3' # Укажите путь к своему файлу\n",
        "audio = AudioSegment.from_mp3(mp3_file)\n",
        "\n",
        "# Конвертация в WAV\n",
        "wav_file = mp3_file.split('.')[0] + '.wav'\n",
        "audio.export(wav_file, format='wav')"
      ],
      "metadata": {
        "id": "H0PsSKWnWdU_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37c66748-1e52-453a-bd68-67507b487e52"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_io.BufferedRandom name='/content/anger.wav'>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Инициализация распознавателя\n",
        "recognizer = sr.Recognizer()\n",
        "\n",
        "# Загрузка WAV-файла\n",
        "audio = AudioSegment.from_wav(wav_file)\n",
        "\n",
        "# Задаем длительность фрагмента для распознавания (30 сек)\n",
        "duration_in_milliseconds = len(audio)\n",
        "fragment_size = 30 * 1000  # 30 секунд\n",
        "\n",
        "# Инициализация пустой строки для собранного текста\n",
        "full_text = \"\"\n",
        "\n",
        "# Разбиение аудио и распознавание каждого фрагмента\n",
        "for start in range(0, duration_in_milliseconds, fragment_size):\n",
        "    end = min(start + fragment_size, duration_in_milliseconds)\n",
        "    audio_fragment = audio[start:end]\n",
        "\n",
        "    # Экспорт фрагмента во временный файл\n",
        "    fragment_file = f\"fragment_{start}_{end}.wav\"\n",
        "    audio_fragment.export(fragment_file, format=\"wav\")\n",
        "\n",
        "    # Распознавание фрагмента\n",
        "    with sr.AudioFile(fragment_file) as source:\n",
        "        audio_data = recognizer.record(source)\n",
        "        try:\n",
        "            text = recognizer.recognize_google(audio_data, language='ru-RU')\n",
        "            full_text += text + \" \"\n",
        "        except sr.UnknownValueError:\n",
        "            print(f\"Фрагмент {start}-{end}: речь не распознана.\")\n",
        "        except sr.RequestError as e:\n",
        "            print(f\"Фрагмент {start}-{end}: ошибка запроса; {e}\")\n",
        "\n",
        "    # Удаление временных файлов\n",
        "    os.remove(fragment_file)\n",
        "\n",
        "# Вывод всего распознанного текста\n",
        "print (len(full_text))\n",
        "print(\"Распознанный текст:\")\n",
        "print(full_text)"
      ],
      "metadata": {
        "id": "DOgzHkkpWhrM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a77afa61-78f1-4c87-a250-b1cd4ca59138"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "89\n",
            "Распознанный текст:\n",
            "I'm so Angry that I feel like I have to go to life not been As Care Free As I want to be \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCEt8XlV_iVF"
      },
      "source": [
        "## Загрузка модели из файла"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('vectorizer.pickle', 'rb') as f:\n",
        "    model_vec = pickle.load(f)"
      ],
      "metadata": {
        "id": "Cvejg1QR87wj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qeLGjjmG_iVF"
      },
      "outputs": [],
      "source": [
        "with open('/content/model.pkl', 'rb') as ff:\n",
        "    model = pickle.load(ff)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YGb82T_pbw0"
      },
      "source": [
        "## Предсказание эмоции для заданного текста"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84gtDeKW_iVF"
      },
      "outputs": [],
      "source": [
        "word = full_text\n",
        "\n",
        "word_tfidf = vectorizer.transform([word])\n",
        "vanga = model.predict(word_tfidf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gDAqRAK_iVF",
        "outputId": "3e6e383d-65fa-4bd5-ae37-4a479ab7ce90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are anger, be happy!\n"
          ]
        }
      ],
      "source": [
        "vanga_answers(vanga)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "_____________________________________________________________________"
      ],
      "metadata": {
        "id": "E99z8SudA1EA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_0UCjBg_iVB"
      },
      "source": [
        "## Загрузка датафрейма"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qfrCmICm_2w6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08067752-1de0-4d36-9e30-364c4870daef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text  label\n",
            "0  i feel awful about it too because it s my job ...      0\n"
          ]
        }
      ],
      "source": [
        "df = open_file('data.jsonl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n2rBpWxz_iVD"
      },
      "outputs": [],
      "source": [
        "#df_sampl = df.head(100).copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pm4nSIw1_iVD"
      },
      "source": [
        "## Train, test, valid\n",
        "Делим датасет на тренировочную, валидационную и тестовую выборки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "iaw8dF15Lyde"
      },
      "outputs": [],
      "source": [
        "X_train, y_train, X_test, X_val, y_test, y_val = train_test_val(df.text, df.label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xC0eUqIy_iVD"
      },
      "source": [
        "## Лемматизация текста"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkK9yPE5Zb53",
        "outputId": "b6bf9ca8-e418-41f0-f6bd-5b63cb890d19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "169233    i once again fail to play it i ll doubtless st...\n",
            "Name: text, dtype: object\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, X_val = lemmatize_text(X_train, X_test, X_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9hfVHTl_iVD"
      },
      "source": [
        "## Удаление стоп-слов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bT1Sin6oYYw4",
        "outputId": "104b8f10-0e35-43ff-e200-7a68a6d290a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "169233    fail play doubtless still feel jealous\n",
            "Name: text, dtype: object\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, X_val = stopwords_text(X_train, X_test, X_val, language = 'english', num_row=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1jVO6uh_iVE"
      },
      "source": [
        "## Преобразование в TF-IDF вектора"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "42q_jo0V-fCu"
      },
      "outputs": [],
      "source": [
        "X_train_tfidf, X_test_tfidf, X_val_tfidf, vectorizer = tf_idf_vec(X_train, X_test, X_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Запись векторайзера в файл"
      ],
      "metadata": {
        "id": "wqIrOIEP_KMZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"vectorizer.pickle\", \"wb\") as ff:\n",
        "    pickle.dump(vectorizer, ff)"
      ],
      "metadata": {
        "id": "0STlNVJD9gWv"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CUm_fuXiDO4"
      },
      "source": [
        "## Обучение модели логистической регрессии"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-yPLtnh0-8xd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e1d5d63-25af-4ac1-d0df-27cf6d3944f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 49/49 [1:44:37<00:00, 128.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Максимальный f1_score = 0.8999273590179936, полученный при значении С = 0.9 на тестовой выборке\n",
            "Максимальный f1_score = 0.9010047840724188, полученный при значении С = 0.8 на валидационной выборке\n",
            "Максимальный accuracy = 0.8971113936805739, полученный при значении С = 0.9 на тестовой выборке\n",
            "Максимальный accuracy = 0.8982629975288501, полученный при значении С = 0.8 на валидационной выборке\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for C in tqdm(np.arange(0.1, 5.0, 0.1)):\n",
        "\n",
        "    model_LogisticRegression_L2 = LogisticRegression(class_weight='balanced',\n",
        "                                                     multi_class='multinomial',\n",
        "                                                     max_iter = 1000,\n",
        "                                                     solver='lbfgs',\n",
        "                                                     penalty='l2',\n",
        "                                                     C=C)\n",
        "    learning_model(X_train_tfidf, y_train, X_val_tfidf, y_val, X_test_tfidf, y_test, model_LogisticRegression_L2, C)\n",
        "print_score(max_f1_test, max_f1_valid, max_acc_test, max_acc_valid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3fpI-cm_iVE"
      },
      "source": [
        "## Запись модели в файл"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s03OKH-3_iVE"
      },
      "outputs": [],
      "source": [
        "with open('model.pkl', 'wb') as f:\n",
        "    pickle.dump(model_LogisticRegression_L2, f)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}